<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Geekheads]]></title>
  <link href="http://www.geekheads.net/atom.xml" rel="self"/>
  <link href="http://www.geekheads.net/"/>
  <updated>2013-07-07T21:40:58-05:00</updated>
  <id>http://www.geekheads.net/</id>
  <author>
    <name><![CDATA[Jack Lund]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Got Them Bluetooth LE Bluez]]></title>
    <link href="http://www.geekheads.net/blog/2013/07/01/Got-Them-Bluetooth-LE-Bluez/"/>
    <updated>2013-07-01T17:15:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/07/01/Got-Them-Bluetooth-LE-Bluez</id>
    <content type="html"><![CDATA[<p>I&rsquo;m trying to get my Raspberry Pi to talk to my <a href="http://www.ti.com/ww/en/wireless_connectivity/sensortag/index.shtml?INTC=SensorTag&amp;HQS=sensortag">TI Sensortag</a> over Bluetooth LE, using an <a href="http://www.iogear.com/product/GBU521/">IOGear Bluetooth 4.0 USB adapter</a>. I chose that adapter because it is supported by Linux, and so far it works quite nicely with the Pi.</p>

<p>To start with, I&rsquo;d like to write something to pull the sensor data &ndash; temperature, humidity, pressure, etc &ndash; from the SensorTag and publish it over <a href="http://mqtt.org/">MQTT</a>. However, reading the data seems to be problematic.</p>

<p>Problem #1 is that the most-used bluetooth package for Python, <a href="https://code.google.com/p/pybluez/">PyBluez</a> had their last release (0.18) in November, 2009, which, obviously, doesn&rsquo;t include Bluetooth LE. Not a problem, I thought, I&rsquo;ll just fork the project, add the bindings for LE, and off we go!</p>

<p>Which brings me to problem #2: the developers of the <a href="http://www.bluez.org/">BlueZ</a> protocol stack, which is how you access bluetooth from, well, pretty much everywhere, haven&rsquo;t seen fit to include <a href="http://en.wikipedia.org/wiki/Bluetooth_profile#Generic_Attribute_Profile_.28GATT.29">GATT</a> support either via a public library or via D-Bus, despite the fact that they&rsquo;ve had the code in their codebase since around 2010.</p>

<p>*<strong><em>facepalm</em></strong>*</p>

<p>Look, I understand that everybody&rsquo;s busy and all, but, really, you couldn&rsquo;t, in the last THREE YEARS break out the GATT code into a library so that people can access it? Really?</p>

<p>Of course, I shouldn&rsquo;t complain, I guess &ndash; they do provide a nice little command-line tool, <code>gatttool</code>, to let you do GATT stuff, just nothing to do, you know, programming with. Somebody (who is much braver than I) is even trying to <a href="https://github.com/msaunby/ble-sensor-pi">access that via Python and pexpect</a>, which works, sort of, but, uh, really, there has to be a better way.</p>

<p>So, I guess my only option is to pull the GATT code out of the BlueZ project and add it to the Python project. It&rsquo;s ugly, but it&rsquo;s better than expect scripts.</p>

<p>And, really, BlueZ developers: Come on, throw us a bone here.</p>

<h3>Update</h3>

<p>Well, it looks like I spoke too soon. Because the BlueZ developers have the GATT-layer stuff hooked heavily into glib 2.0 using callbacks, it would be much more work than I&rsquo;m willing to put into it to do this within Python, which probably explains why nobody else has done it either. Thanks again, BlueZ team! <em>sigh</em></p>

<p>So, I guess what I&rsquo;m going to have to end up doing is writing all this in C/C++, and pulling parts of their GATT code into my project. Either that, or just implementing the parts I need myself.</p>

<p>My guess is that the BlueZ developers are really more interested in writing kernel code than user-space code. It really sucks for anybody who wants to play with LE applications, though &ndash; right now everybody seems to be just writing wrappers around the BlueZ command-line apps and calling it a day. Not a great way to help with adoption of a standard, guys!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zeroconf Rocks!]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/27/Zeroconf-Rocks/"/>
    <updated>2013-06-27T22:27:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/27/Zeroconf-Rocks</id>
    <content type="html"><![CDATA[<p>I have a lot of computers on my network now &ndash; my laptop and desktop, my wife&rsquo;s 3(!) computers, her iPad, two Linux servers and miscellaneous other devices, along with my Raspberry Pi and two BeagleBone Blacks, so managing all these was starting to be a pain. So, just on a hunch, I wanted to see if <a href="http://en.wikipedia.org/wiki/Zero-configuration_networking">Bonjour/Zeroconf/Avahi</a> could help. I did some investigation, and it turns out that you can access any machines that advertise on Zeroconf by <em>name</em>.local. Since I work predominantly on Macs, I was already pretty comfortable with the idea of dynamically finding service. When I brought up my Bonjour Browser application, however, I was surprised: My two BeagleBone Blacks were already advertising (the wrong IP address for my network, but still)!</p>

<p>So, first step: set up the Raspberry Pi to do the same. Fortunately, the Internet came to the rescue, in the form of <a href="http://elinux.org/RPi_Advanced_Setup">this page</a> about setting up Zeroconf on the Pi. I just followed the instructions, and it worked.</p>

<p>Next, I had to fix my BeagleBone Blacks. To do this, I found the DHCP daemon config file, <code>/etc/udhcpd.conf</code>, which looked like this:</p>

<pre><code>start      192.168.7.1
end        192.168.7.1
interface  usb0
max_leases 1
option subnet 255.255.255.252
</code></pre>

<p>and which I changed to match my network:</p>

<pre><code>start      192.168.1.2
end        192.168.1.99
interface  usb0
max_leases 1
option subnet 255.255.255.0
</code></pre>

<p>Then, I just restarted them, and they suddenly had the right IP addresses.</p>

<p>Now, all I have to do to SSH into my Pi is do <code>ssh raspberry-pi.local</code>. For my BeagleBones, it would be <code>ssh beaglebone-red.local</code> or <code>ssh beaglebone-blue.local</code>.</p>

<p>W00t!!!!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala Is Disappointing]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/25/Scala-Is-Disappointing/"/>
    <updated>2013-06-25T00:15:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/25/Scala-Is-Disappointing</id>
    <content type="html"><![CDATA[<p>So, I&rsquo;ve been playing around with Scala, and, while I&rsquo;m quite impressed with the language syntax, it&rsquo;s a real pain-in-the-ass to deal with. To begin with, the various versions (2.7, 2.8, 2.9., 2.10) are <a href="http://lift.la/scalas-version-fragility-make-the-enterprise">binary incompatible</a>, which is really annoying. I understand that the language is still in development, but you would think they&rsquo;d have the core of the language all worked out by now.</p>

<p>I understand the <a href="http://suereth.blogspot.com/2011/12/scala-fresh-is-alive.html">reasons behind it</a>: they&rsquo;re still making changes to the base traits which causes all the objects to change. But, really, this is one of those things that every language (well, every language with a base class or interface) goes through. These are the things you go through, however, when you&rsquo;re doing the pre-1.0 releases of the language, not 2.x; at most, you make these changes when you transition between major revisions &ndash; from 2.x to 3.0, for instance &ndash; <em>not</em> between minor revisions.</p>

<p>What concerns me with this, besides the PIA factor, is that a) the language developers don&rsquo;t seem to think this is a problem, and b) that it indicates a tendency to want to &ldquo;fiddle&rdquo; with the language. I understand the desire to &ldquo;fiddle&rdquo;, it&rsquo;s one of those things that every software developer goes through, the desire to &ldquo;tweak it just a little bit more&rdquo; after it&rsquo;s released. It&rsquo;s also one of those things that mature software developers grow out of. &ldquo;The perfect is the enemy of the good&rdquo;.</p>

<p>They don&rsquo;t seem to realize that this is going to make it <em>really</em> hard for it to be taken seriously as a general-purpose language. When you&rsquo;re trying to make a business case for using a new language, one of the things that you have to demonstrate is that the language is mature enough to not change out from under you. Scala is changing constantly, and the Scala developers seem to think this is a virtue, rather than a problem.</p>

<p>Why is this a problem? Well, the fact that you have Scala libraries having to label themselves with the version of Scala they&rsquo;re compiled against is an immediate indication. If I&rsquo;m trying to do a project that&rsquo;s dependent on libraries, I now have to make absolutely sure that there is some version of Scala that they&rsquo;re all compatible with, and then use that version for my project, rather than using the version based on the feature set I need. What&rsquo;s more, if there is no overlap &ndash; if one of my dependencies is only compatible with, say, 2.9, and another only builds on 2.7, then I&rsquo;m hosed. I either have to try to build one or the other on a different version of the compiler, which may or may not work, or use different libraries.</p>

<p>The other bit of craziness is the Eclipse Scala plugin can&rsquo;t change versions, and, you can&rsquo;t have more than one version running at a time. Even more fun: the only Scala plugins for Eclipse Juno are for 2.9 and 2.10 &ndash; if you have to use 2.8, you&rsquo;re either going to have to use Indigo, or cross-compile to a newer version of Scala.</p>

<p>All in all, I&rsquo;d have to say that, as much as I like the idea of Scala, I can&rsquo;t see using it for anything significant until it becomes more stable.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala Development Setup]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/21/Scala-Development-Setup/"/>
    <updated>2013-06-21T21:56:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/21/Scala-Development-Setup</id>
    <content type="html"><![CDATA[<p>I had this idea for doing a Scala project integrating WebSockets with <a href="http://kafka.apache.org/">Kafka</a>, so I spent a good bit of today trying out different configurations for doing Scala development. My first pass was to try <a href="http://www.jetbrains.com/idea/features/scala.html">IntellijIDEA</a> from JetBrains. I really liked their <a href="http://www.jetbrains.com/ruby/">RubyMine</a> IDE for Ruby, and people were raving about IDEA for Scala development, so I gave it a go.</p>

<p>It&rsquo;s actually not a bad IDE. I had some trouble navigating, but most of that was because I was so used to Eclipse. However, the big thing that was lacking was good <a href="http://www.scala-sbt.org/">sbt</a> support. Whatever project I was going to use sbt, since that seems to be the builder of choice, and the integration with IDEA seemed to be, well, not really good. You can use sbt to generate the IDEA project, but there didn&rsquo;t seem to be a good way to have IDEA use the dependencies defined in the sbt build file for the code completion, which seemed to me to be a big problem.</p>

<p>So, I tried out using Eclipse (which wasn&rsquo;t a stretch since I use it for my Java work), and <a href="https://github.com/typesafehub/sbteclipse">sbteclipse</a>, which is an sbt plugin for Eclipse. It worked really well! Basically, you install the plugin per the instructions, create a minimal sbt build file for the project, and then type <code>sbt eclipse</code> to generate the Eclipse configuration. The cool thing is, you can do this at any time, so if you add a dependency to the build file, just do <code>sbt eclipse</code> again, then refresh the project in Eclipse, and suddenly it has your dependency. Very nice.</p>

<p>The one thing I needed to do, which I eventually found out how to do, was to have sbt use my local maven repository as one of its repositories. sbt uses <a href="http://ant.apache.org/ivy/">ivy</a> under the covers, so Maven integration is there, it just doesn&rsquo;t know about all the local Maven repositories. to add it, I just had to add the following to my <code>~/.sbt/global.sbt</code> file:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resolvers += "Local Maven Repository" at "file://"+Path.userHome.absolutePath+"/.m2/repository"</span></code></pre></td></tr></table></div></figure>


<p>and, voila, it worked!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Eclipse with Subversion 1.8 on OS X]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/18/eclipse-with-subversion-1-dot-8-on-os-x/"/>
    <updated>2013-06-18T14:14:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/18/eclipse-with-subversion-1-dot-8-on-os-x</id>
    <content type="html"><![CDATA[<p>I wasted a considerable amount of time following the instructions from <a href="http://subclipse.tigris.org/wiki/JavaHL">this page</a> on how to install Subclipse on OS X, trying to get MacPorts to install the right version of Subversion (Why subversion, you may ask? Because a customer is still using it, that&rsquo;s why&hellip;).</p>

<p>It turns out that MacPorts doesn&rsquo;t even have the 1.8 version of Subversion &ndash; it&rsquo;s only got 1.7, which won&rsquo;t work with the version of Subclipse I&rsquo;m using. So, I had to go to <a href="http://www.wandisco.com/subversion/download#osx">WanDisco</a> and download it (after removing the MacPorts versions first), and then everything worked.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moved to GitHub/Octopress]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/18/moved-to-github-slash-octopress/"/>
    <updated>2013-06-18T10:51:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/18/moved-to-github-slash-octopress</id>
    <content type="html"><![CDATA[<p>I finally gave up on <a href="http://www.scriptogr.am">scriptogr.am</a>. I was struggling with their syntax highlighting, even sent a message to their support. The only answer I got back was from another user (who was very helpful, but it didn&rsquo;t really fix my problem). So, I&rsquo;m done.</p>

<p>I&rsquo;m now using <a href="http://pages.github.com/">GitHub Pages</a>, which generates their pages using <a href="https://github.com/mojombo/jekyll">Jekyll</a>. I&rsquo;m also using <a href="http://octopress.org/">Octopress</a> for the layout, which makes it all pretty easy (well, that is, once you go through the somewhat painful ruby setup).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SELinux and SSH]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/13/SELinux-and-SSH/"/>
    <updated>2013-06-13T13:30:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/13/SELinux-and-SSH</id>
    <content type="html"><![CDATA[<p>I needed to set up Jenkins so that it could run an agent on another Linux box. To do this the default way, you need to allow Jenkins to access the remote box via SSH. So, I set up the Jenkins user and the SSH keys on the remote machine, but trying to do an ssh from the Jenkins user on one machine to the other still didn&rsquo;t work. After doing <code>sudo journalctl -f</code> on the remote machine, I saw the following:</p>

<pre><code>Jun 13 12:41:50 m2m-linux setroubleshoot[701]: SELinux is preventing /usr/sbin/sshd from read access on the file authorized_keys. For complete SELinux messages. run sealert -l ca7b7aea-64cf-46e5-8bfa-6650ad23f55b
</code></pre>

<p>Running the suggested <code>sealert -l ca7b7aea-64cf-46e5-8bfa-6650ad23f55b</code> gave me the following (edited for brevity):</p>

<pre><code>SELinux is preventing /usr/sbin/sshd from read access on the file authorized_keys.

*****  Plugin catchall_labels (83.8 confidence) suggests  ****

If you want to allow sshd to have read access on the authorized_keys file
Then you need to change the label on authorized_keys
Do
# semanage fcontext -a -t FILE_TYPE 'authorized_keys'
where FILE_TYPE is one of the following: NetworkManager_etc_rw_t, NetworkManager_etc_t,...
Then execute:
restorecon -v 'authorized_keys'


*****  Plugin catchall (17.1 confidence) suggests  *************

If you believe that sshd should be allowed read access on the authorized_keys file by default.
Then you should report this as a bug.
You can generate a local policy module to allow this access.
Do
allow this access for now by executing:
# grep sshd /var/log/audit/audit.log | audit2allow -M mypol
# semodule -i mypol.pp
</code></pre>

<p>Not really helpful, so I dug around the web and found <a href="http://serverfault.com/questions/50573/selinux-preventing-passwordless-ssh-login">this post on ServerFault</a>. It turns out that the problem is that I created the Jenkins user&rsquo;s home directory by hand (I had to, it was <code>/var/jenkins</code>, which <code>adduser</code> wouldn&rsquo;t create), so SELinux didn&rsquo;t know it was a home directory.</p>

<p>To fix this, I added the following lines to the end of <code>/etc/selinux/targeted/contexts/files/file_contexts.homedirs</code>:</p>

<pre><code>/var/jenkins/.+ unconfined_u:object_r:user_home_t:s0
/var/jenkins/\.ssh(/.*)?      system_u:object_r:ssh_home_t:s0
</code></pre>

<p>and then did <code>sudo restorecon -R -v /var/jenkins</code>, and that fixed the problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Node.js]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/12/Node.js/"/>
    <updated>2013-06-12T16:10:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/12/Node.js</id>
    <content type="html"><![CDATA[<p>Having my new <a href="http://www.geekheads.net/jacklund/post/beaglebone-black">BeagleBone Black</a> has made me look at the default programming environment for it, <a href="http://nodejs.org">Node.js</a>. Companies like <a href="http://www.linkedin.com">LinkedIn</a> are <a href="http://engineering.linkedin.com/nodejs/blazing-fast-nodejs-10-performance-tips-linkedin-mobile">using it</a> on the server side, which sort of surprises me. I can definitely see its uses in devices like the BeagleBone, since it has such a small footprint and minimal use of resources, but I was surprised at how many people are using it on the server side.</p>

<p>It makes sense, though &ndash; as <a href="http://wiki.nginx.org/Main">Nginx</a> demonstrated, an event-driven model can eat a thread-based server&rsquo;s lunch, performance-wise, under certain circumstances. What are those circumstances, though?</p>

<p>To begin with, your application would have to be overwhelmingly I/O-bound; anything that does a lot of CPU operations would gain no real benefit from the event-driven model. So, for example, an application which receives requests and stores data in the database without a lot of processing would work really well here. Why? Because in a thread-based model, you would spawn a thread to handle the request, and that thread would be waiting, doing, basically, nothing while waiting for the database request to return. In the Node.js model, you would handle the incoming request, send off an asynchronous call for the database insert, registering a callback, and then handle the next event.</p>

<p>However, if you were doing a lot of processing of the data, your event handler would be running longer than you would really like, and the other requests might get starved. You could get around this by offloading the processing to another service, so you would send off the request, and go about your business until the response came back, and you could respond to your client.</p>

<p>This is all very interesting, and it would be even more interesting to do some performance comparisons of a &ldquo;traditional&rdquo; app written in something like Java vs. a Node.js app.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting up NTP on BeagleBone Black]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/10/Setting-up-NTP-on-BeagleBone-Black/"/>
    <updated>2013-06-10T11:50:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/10/Setting-up-NTP-on-BeagleBone-Black</id>
    <content type="html"><![CDATA[<p>For some reason, they didn&rsquo;t seem to see the need to set up the time service on the BeagleBone Blacks by default. I tried using the instructions from <a href="http://derekmolloy.ie/automatically-setting-the-beaglebone-black-time-using-ntp/">this gentleman</a>, but I had to make some modifications.</p>

<ol>
<li>Install NTP</li>
</ol>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>    <span class="nv">$ </span>opkg update <span class="o">&amp;&amp;</span> opkg install ntp
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Edit <code>/etc/ntp.conf</code>, adding <code>pool.ntp.org</code> as the server:</li>
</ol>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='apache'><span class='line'>    <span class="c"># This is the most basic ntp configuration file</span>
</span><span class='line'>    <span class="c"># The driftfile must remain in a place specific to this</span>
</span><span class='line'>    <span class="c"># machine - it records the machine specific clock error</span>
</span><span class='line'>    <span class="nb">driftfile</span> <span class="sx">/etc/ntp.drift</span>
</span><span class='line'>    <span class="c"># This obtains a random server which will be close</span>
</span><span class='line'>    <span class="c"># (in IP terms) to the machine.  Add other servers</span>
</span><span class='line'>    <span class="c"># as required, or change this.</span>
</span><span class='line'>    <span class="nb">server</span> pool.ntp.org
</span><span class='line'>    <span class="c"># Using local hardware clock as fallback</span>
</span><span class='line'>    <span class="c"># Disable this when using ntpd -q -g -x as ntpdate or it will sync to itself</span>
</span><span class='line'>    <span class="nb">server</span> <span class="m">127.127.1.0</span>
</span><span class='line'>    <span class="nb">fudge</span> <span class="m">127.127.1.0</span> stratum <span class="m">14</span>
</span><span class='line'>    <span class="c"># Defining a default security setting</span>
</span><span class='line'>    <span class="nb">restrict</span> default
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Set your local time:</li>
</ol>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>    <span class="nv">$ </span><span class="nb">cd</span> /etc
</span><span class='line'>    <span class="nv">$ </span>rm -f localtime
</span><span class='line'>    <span class="nv">$ </span>ln -s ../usr/share/zoneinfo/America/Chicago localtime
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Edit <code>/etc/default/ntpdate</code>:</li>
</ol>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='apache'><span class='line'>    <span class="c"># Configuration script used by ntpdate-sync script</span>
</span><span class='line'>
</span><span class='line'>    <span class="err">NTPSERVERS=&quot;pool</span>.<span class="err">ntp</span>.<span class="err">org&quot;</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Set to &quot;yes&quot; to write time to hardware clock on success</span>
</span><span class='line'>    <span class="err">UPDATE_HWCLOCK=&quot;yes&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<ol>
<li>Now, reboot and see if the clock gets set correctly</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BeagleBone Black]]></title>
    <link href="http://www.geekheads.net/blog/2013/06/09/BeagleBone-Black/"/>
    <updated>2013-06-09T20:00:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/06/09/BeagleBone-Black</id>
    <content type="html"><![CDATA[<p>Got my two <a href="http://beagleboard.org/Products/BeagleBone%20Black">BeagleBone Blacks</a> from <a href="http://adafruit.com/">AdaFruit</a> on Friday. Really nice. I bought them without enclosures because, well, the enclosures were $20, and the BeagleBones themselves were only $45. The nice thing is, though, that they fit exactly into an Altoids tin, so I turned two into my enclosures. I used tin snips to cut holes for power and Ethernet, and lined them with electrical tape to insulate the board from the box. Here&rsquo;s what they ended up looking like:</p>

<p><img src="https://dl.dropbox.com/s/bpgc7lc5azhazw5/altoids_closed.jpg" title="Closed" alt="" /></p>

<p><img src="https://dl.dropbox.com/s/d87y38ydxqtcv2q/altoids_open.jpg" title="Open" alt="" /></p>

<p><img src="https://dl.dropbox.com/s/7nocbp8nnb65pwn/altoids_working.jpg" title="Running" alt="" /></p>

<p>By default, they run <a href="http://www.angstrom-distribution.org/">Ångström Linux</a>. The default programming environment for them is a variant of Javascript they call <a href="http://beagleboard.org/Support/BoneScript">&ldquo;Bonescript&rdquo;</a>, which runs via <a href="http://nodejs.org/">Node.js</a>. However, a kind soul had put together a Python library called <a href="https://github.com/alexanderhiam/PyBBIO">PyBBIO</a>, which I downloaded and tried to install. I kept getting the following warning, however:</p>

<pre><code>Warning: you seem to have a BeagleBone image which only has drivers for the PWM1 module, PWM2A and PWM2B will not be available in PyBBIO.
You should consider updating Angstrom!
</code></pre>

<p>I tried updating the OS using <a href="http://learn.adafruit.com/beaglebone-black-installing-operating-systems/overview">these instructions</a>, however it didn&rsquo;t make the problem go away. That&rsquo;s when I discovered that PyBBIO <a href="https://github.com/alexanderhiam/PyBBIO/issues/18">doesn&rsquo;t support the 3.8 kernel that comes with BB Blacks</a>, so it looks like I&rsquo;m stuck with Javascript for the moment.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[I Hate LaTeX]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/30/I-Hate-LaTeX/"/>
    <updated>2013-05-30T11:30:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/30/I-Hate-LaTeX</id>
    <content type="html"><![CDATA[<p>No, I really do. It&rsquo;s not hyperbole. I hate it.</p>

<p>It&rsquo;s frickin&#8217; 2013, people. We should not have to deal with languages that look like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='latex'><span class='line'><span class="k">\renewcommand</span><span class="nb">{</span><span class="k">\href</span><span class="nb">}</span>[2]<span class="nb">{</span>#2<span class="k">\footnote</span><span class="nb">{</span><span class="k">\url</span><span class="nb">{</span>#1<span class="nb">}}}</span>
</span><span class='line'><span class="s">$</span><span class="nb">endif</span><span class="s">$</span>
</span><span class='line'><span class="s">$</span><span class="nb">if</span><span class="o">(</span><span class="nb">strikeout</span><span class="o">)</span><span class="s">$</span>
</span><span class='line'><span class="k">\usepackage</span><span class="na">[normalem]</span><span class="nb">{</span>ulem<span class="nb">}</span>
</span><span class='line'><span class="c">% avoid problems with \sout in headers with hyperref:</span>
</span><span class='line'><span class="k">\pdfstringdefDisableCommands</span><span class="nb">{</span><span class="k">\renewcommand</span><span class="nb">{</span><span class="k">\sout</span><span class="nb">}{}}</span>
</span><span class='line'><span class="s">$</span><span class="nb">endif</span><span class="s">$</span>
</span><span class='line'><span class="k">\setlength</span><span class="nb">{</span><span class="k">\parindent</span><span class="nb">}{</span>0pt<span class="nb">}</span>
</span><span class='line'><span class="k">\setlength</span><span class="nb">{</span><span class="k">\parskip</span><span class="nb">}{</span>6pt plus 2pt minus 1pt<span class="nb">}</span>
</span><span class='line'><span class="k">\setlength</span><span class="nb">{</span><span class="k">\emergencystretch</span><span class="nb">}{</span>3em<span class="nb">}</span>  <span class="c">% prevent overfull lines</span>
</span><span class='line'><span class="s">$</span><span class="nb">if</span><span class="o">(</span><span class="nb">numbersections</span><span class="o">)</span><span class="s">$</span>
</span><span class='line'><span class="k">\setcounter</span><span class="nb">{</span>secnumdepth<span class="nb">}{</span>5<span class="nb">}</span>
</span><span class='line'><span class="s">$</span><span class="nb">else</span><span class="s">$</span>
</span><span class='line'><span class="k">\setcounter</span><span class="nb">{</span>secnumdepth<span class="nb">}{</span>0<span class="nb">}</span>
</span><span class='line'><span class="s">$</span><span class="nb">endif</span><span class="s">$</span>
</span></code></pre></td></tr></table></div></figure>


<p>and parsers that give errors like this:</p>

<pre><code>paragraph ended before Gin@iii was completed.
</code></pre>

<p>The reason I&rsquo;m even messing with this is that I want a way to convert <a href="http://daringfireball.net/projects/markdown/">markdown</a> to PDF. Should be easy, right?</p>

<p>Guess again. Just about everything either converts from markdown to HTML, then to PDF, which renders pretty badly, or from markdown to LaTeX to PDF, which renders rather nicely. Except, in order to tweak it (like adding a logo to the title) you have to hack LaTeX. Ugh.</p>

<p>One of the most flexible converters, <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>, which, don&rsquo;t get me wrong, is a very nice package, requires you to tweak a <code>default.latex</code> file to modify the default format, hence my problem: I just spent around an hour and a half just trying to get a frickin&#8217; logo on the cover page where I want it (there&rsquo;s a LaTeX package called &ldquo;titlepic&rdquo; which puts it where <em>it</em> wants, but if you want it elsewhere, you&rsquo;re SOL).</p>

<p>Again, it&rsquo;s 2013 and document creation shouldn&rsquo;t be frickin&#8217; rocket science! The whole point of writing in markdown is that we don&rsquo;t want to have to mess with complex document formats. I should be able to take a markdown document, pass it into a converter, give it some options in a syntax that doesn&rsquo;t look like 80&rsquo;s-era gobbledygook, and get a decent-looking document out the other end.</p>

<p><em>facepalm</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating RESTEasy Project with Eclipse and Maven]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/20/Creating-RESTEasy-Project-with-Eclipse-and-Maven/"/>
    <updated>2013-05-20T00:00:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/20/Creating-RESTEasy-Project-with-Eclipse-and-Maven</id>
    <content type="html"><![CDATA[<p>Handy safety tip: to create a RESTEasy-friendly Maven project in Eclipse, do the following:</p>

<ol>
<li>Create the project as a simple Maven project</li>
<li>In the project Properties &ndash;> Project Facets, make the project faceted, and select &ldquo;Dynamic Web Module&rdquo; (you may get a NullPointerException, but it doesn&rsquo;t seem to matter). Under &ldquo;Further Configuration&hellip;&rdquo;, point the WebApp directory to be <code>src/main/webapp</code>, and have it create the <code>web.xml</code> file.</li>
<li>Under &ldquo;Web Content Settings&rdquo;, set the Context root</li>
<li>Under &ldquo;Deployment Assembly&rdquo;, select &ldquo;Add&hellip;&rdquo;, select &ldquo;Java Build Path Entries&rdquo;, and select &ldquo;Maven Dependencies&rdquo;. It should put them in <code>WEB-INF/lib</code>.</li>
<li>Add the code and the dependencies to the <code>pom.xml</code>. Make sure to add the RESTEasy stuff to the <code>web.xml</code> file.</li>
</ol>


<p>You should be able to deploy it from Eclipse into Tomcat without any issues</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TI SensorTag]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/12/TI-SensorTag/"/>
    <updated>2013-05-12T19:20:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/12/TI-SensorTag</id>
    <content type="html"><![CDATA[<p>I got my <a href="http://processors.wiki.ti.com/index.php/Bluetooth_SensorTag">TI Bluetooth SensorTag</a> Friday, and played with it some over the weekend. It&rsquo;s pretty nice. It&rsquo;s basically a small device with a bunch of embedded sensors on it &ndash; accelerometer, gyroscope, ambient temp, IR temp (see below), humidity, barometric pressure, and a couple of buttons on it. It&rsquo;s very small, and communicates over <a href="http://en.wikipedia.org/wiki/Bluetooth_low_energy">Bluetooth 4 LE</a>. You can download an iOS app for viewing the data, so my daughters and I played with it some. Pretty cool. There&rsquo;s a <a href="http://blog.makezine.com/2013/04/18/teardown-of-the-ti-sensortag">teardown of it</a> at MAKE magazine, and even a <a href="http://mike.saunby.net/2013/04/raspberry-pi-and-ti-cc2541-sensortag.html">Raspberry Pi</a> project to interface with it. W00t!!!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Falling in Love with Git]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/07/Falling-in-Love-with-Git/"/>
    <updated>2013-05-07T17:00:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/07/Falling-in-Love-with-Git</id>
    <content type="html"><![CDATA[<p>As I mentioned earlier, we&rsquo;re transitioning from subversion to git, and one of the things we need to do is convert from many-projects-per-repository, which is what we had in subversion, to one-project-per-repository for git. This is partly to make things nicer, and partly because it will make <a href="http://jenkins-ci.org/">Jenkins</a> work better. So, thinking in subversion-terms, I thought I&rsquo;d have to do it myself, and even tried by renaming all the files in one of the projects into the upper-level directory, removing all the other projects, committing locally, and then pushing to a new repo. Royal pain.</p>

<p>And then, I came across <a href="https://help.github.com/articles/splitting-a-subpath-out-into-a-new-repository">this</a>. Oh. My. God. Git actually does the work for you. It&rsquo;s so easy, you just do the <code>git filter-branch</code> command, and suddenly your project is its own repository! Then, you just change the remote repository (<code>git remote rm origin</code> followed by <code>git remote add</code> <em>new-url</em>), and Bob&rsquo;s your uncle, you have a new, smaller repository.</p>

<p>I mean, seriously? That is AWESOME!</p>

<p>So, to be explicit, here&rsquo;s the series of commands:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>git clone repo-url
</span><span class='line'><span class="nv">$ </span><span class="nb">cd </span>repo
</span><span class='line'><span class="nv">$ </span>git filter-branch --prune-empty --subdirectory-filter subdir-name master
</span><span class='line'><span class="nv">$ </span>git remote rm origin
</span><span class='line'><span class="nv">$ </span>git remote add new-repo-url
</span><span class='line'><span class="nv">$ </span>git push -u origin --all --tags
</span></code></pre></td></tr></table></div></figure>


<p><strong>Updated 05/12/2013</strong>
Okay, after messing around with this for some time, I&rsquo;ve discovered that the above doesn&rsquo;t work quite right, because the pathnames in the commits are wrong &ndash; instead of being <em>subdir-name</em><code>/src/foo/Bar.java</code>, it ends up being <code>src/foo/Bar.java</code>, which doesn&rsquo;t work. So, instead of trying to pull each subdirectory into their own repository, I&rsquo;m taking the existing repository, with a bunch of subdirs, including the ones I&rsquo;m interested in, and simply using <code>git filter-branch</code> to get rid of the ones I&rsquo;m not interested in, as well as update the tags. So, here&rsquo;s what I&rsquo;ve got now, which seems to work well:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Get a list of the directories I&#39;m not interested in</span>
</span><span class='line'><span class="nv">$ excludes</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="nv">$*</span> | tr <span class="s2">&quot; &quot;</span> <span class="s2">&quot;|&quot;</span><span class="sb">`</span>
</span><span class='line'><span class="nv">$ files</span><span class="o">=</span><span class="sb">`</span>ls | egrep -v <span class="nv">$excludes</span> | tr <span class="s2">&quot;\\n&quot;</span> <span class="s2">&quot; &quot;</span><span class="sb">`</span>
</span><span class='line'><span class="c"># Disconnect from remote for safety</span>
</span><span class='line'><span class="nv">$ </span>git remote rm origin
</span><span class='line'><span class="c"># Get rid of all tags that don&#39;t fit my pattern</span>
</span><span class='line'><span class="nv">$ </span>git tag -l | grep -v <span class="nv">$pattern</span> | xargs git tag -d
</span><span class='line'><span class="c"># Prune the directories I&#39;m not interested in</span>
</span><span class='line'><span class="nv">$ </span>git filter-branch --tag-name-filter cat --prune-empty <span class="se">\</span>
</span><span class='line'>    --tree-filter <span class="s2">&quot;rm -rf ${files}&quot;</span> -- --all
</span><span class='line'><span class="c"># Reset the indexes</span>
</span><span class='line'><span class="nv">$ </span>git reset --hard
</span><span class='line'><span class="c"># Get rid of obsolete references in the logs</span>
</span><span class='line'><span class="nv">$ </span>git <span class="k">for</span>-each-ref --format<span class="o">=</span><span class="s2">&quot;%(refname)&quot;</span> refs/original/ | <span class="se">\</span>
</span><span class='line'>    xargs -n 1 git update-ref -d
</span><span class='line'><span class="nv">$ </span>git reflog expire --expire<span class="o">=</span>now --all
</span><span class='line'><span class="nv">$ </span>git gc --aggressive --prune<span class="o">=</span>now
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Airport Extreme]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/06/Airport-Extreme/"/>
    <updated>2013-05-06T22:05:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/06/Airport-Extreme</id>
    <content type="html"><![CDATA[<p>Had to replace my old, crappy Netgear router over the weekend &ndash; it was getting flaky, and causing my Skype calls to freak out at inopportune moments. I was thinking about going the <a href="http://en.wikipedia.org/wiki/DD-WRT">DD-WRT</a> route (if you&rsquo;ll excuse the pun), but it looked like it required more of a time commitment than I am able to manage at the moment. Since almost everything we have in this house is some form of Apple product, I decided to try out the Airport Extreme.</p>

<p>Man, was that thing easy to set up, especially compared to the Living Hell that is most router setups. I just went into Airport Utility on my laptop, it automagically found the router, I configured it right there, and it just frickin&#8217; worked! Unbelievable! Admittedly, it&rsquo;s a pricey router, but I think it&rsquo;s worth it with the time it saved me.</p>

<p>It also seems to be a <strong>lot</strong> more powerful than those underpowered Netgear POSes, which is an added benefit.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VerifyError with JDK 7]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/06/VerifyError-with-JDK-7/"/>
    <updated>2013-05-06T21:43:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/06/VerifyError-with-JDK-7</id>
    <content type="html"><![CDATA[<p>We had been using nothing higher than JDK 6 with our project up until now, but when I built a new build machine using Fedora 18, JDK 7 was our only real option (okay, that and JDK 5). However, once I got things building using ant, I got the following cryptic error in the unit tests:</p>

<pre><code>java.lang.VerifyError: Expecting a stackmap frame at branch target 41 in method com.m2mci.correlation.CorrelationId.equals(Ljava/lang/Object;)Z at offset 24
</code></pre>

<p>After some <a href="http://www.javacraft.org/2012/07/cobertura-with-jdk7.html">digging</a>, I found out that the kind folks at Oracle/Sun had changed the bytecode in JDK 7 such that there was a verifier frame now included where there wasn&rsquo;t before. This is fine as long as everything knows about this, but we&rsquo;ve been using <a href="http://cobertura.sourceforge.net/">Cobertura</a> for code coverage, which instruments the bytecode, and which apparently doesn&rsquo;t know about the fancy new verifier stack frame. What&rsquo;s worse, they don&rsquo;t seem (from what I can tell from their website) to have any interest in adding it any time soon.</p>

<p>So, what to do? Our two alternatives are a) drop Cobertura, or b) include the JVM argument <code>-XX:-UseSplitVerifier</code> every time we run our code. To me, the former seems the better way to go, especially since we&rsquo;re not really <em>using</em> code coverage right now (we probably should, but for now, we&rsquo;re not).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Getting Jenkins on Windows Working with Git]]></title>
    <link href="http://www.geekheads.net/blog/2013/05/06/Getting-Jenkins-on-Windows-Working-with-Git/"/>
    <updated>2013-05-06T20:46:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/05/06/Getting-Jenkins-on-Windows-Working-with-Git</id>
    <content type="html"><![CDATA[<p>We&rsquo;re transitioning, as a company, from Subversion to Git, which is a Good Thing, but has its complications. One of them was getting <a href="http://jenkins-ci.org/">Jenkins</a>, which we use for <a href="http://en.wikipedia.org/wiki/Continuous_integration">continuous integration</a>, to work with our Git repositories.</p>

<p>I had started out by thinking that I would have to create a user in our repository provider (we&rsquo;re using <a href="http://bitbucket.org">BitBucket</a>) which would have read permisisons to our repositories, a &ldquo;jenkins&rdquo; user. Turns out its not the case. All you need to do for read-only access is to generate SSH keys that you register with the repository, and which Jenkins uses to clone the repository.</p>

<p>On Linux, this would be trivial. On Windows, of course, very little is trivial.</p>

<p>So, following <a href="http://computercamp.cdwilson.us/jenkins-git-clone-via-ssh-on-windows-7-x64">this guide</a>(with some modifications) I managed it this way:</p>

<ol>
<li>Install <a href="http://git-scm.com/downloads">Git</a></li>
<li>Generate the new SSH keys on my local machine using <code>ssh-keygen</code>. Make sure to specify a file <strong>other</strong> than the default (unless you like the idea of overwriting any existing keys you might have).</li>
<li>Install the public key in the repository. In BitBucket, you do this under the account settings for the user or group who owns the repositories. Do it at the user/group level, not at the repository level (unless you want separate keys for each repository). Just cut and paste the contents of the public key to the web page, and click &ldquo;Add&rdquo;</li>
<li>Install <a href="http://technet.microsoft.com/en-us/sysinternals/bb896649.aspx">PsTools</a> (<em>Note</em>: the link given in the guide mentioned above didn&rsquo;t work for me). Extract the zip file wherever you want (I put mine in the root dir)</li>
<li>Run the following in a command shell <em>running as administrator</em>: <code>\PsTools\PsExec.exe -i -s cmd.exe</code> (<em>Note:</em> the guide says use a normal shell, but that will fail the first time, because it tries to instal something that needs Admin privileges). To do this, find the command shell icon in the menu, right-click, and select <em>Run as Administrator&hellip;</em>.</li>
<li>Do <code>echo %USERPROFILE%</code> in the shell to find out where the system user (and, hence, Jenkins) runs from as its home directory. Mine turned out to be <code>C:\Windows\system32\config\systemprofile</code>. YMMV.</li>
<li>Make a folder named <code>.ssh</code> in that home directory</li>
<li>Copy the keys (private and public) to the Windows machine in the <code>.ssh</code> folder</li>
<li>Run <code>"C:\Program Files(x86)\Git\bin\ssh.exe" -T git@bitbucket.org</code> (<em>Note:</em> the location of git on your install may be different than mine). When you get the usual &ldquo;unknown host&rdquo; warning, type &ldquo;yes&rdquo; to get the server key in your known_hosts file</li>
<li>Finally, test git by doing a <code>git ls-remote git@bitbucket.org:repo.git HEAD</code></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking Architecture]]></title>
    <link href="http://www.geekheads.net/blog/2013/04/11/Rethinking-Architecture/"/>
    <updated>2013-04-11T22:30:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/04/11/Rethinking-Architecture</id>
    <content type="html"><![CDATA[<p>So, I&rsquo;ve been rethinking the architecture we used with a customer, and which we are planning on using, in slightly modified form, for some in-house projects.</p>

<p>The application is, basically, a cloud-based service which takes data from devices, analyzes and stores it, and presents it to the user in a web site.</p>

<p>We had decided, early on, to go with Java as our language of choice, both because it was what the customer was comfortable with, and because we felt like it offered the best performance/flexibility tradeoff (and, yes, performance is an issue here, especially on the data collection side).</p>

<p>The pieces of our architecture include:</p>

<ul>
<li>A <a href="https://en.wikipedia.org/wiki/Rest">RESTful</a> web service, to both collect the data and to serve as an API for apps which want to access the data</li>
<li>Some sort of queuing mechanism for taking the data in, and processing it on the back end asynchronously</li>
<li>A database of some sort for storing the readings</li>
<li>A website, utilizing static HTML and Javascript for accessing and presenting the data, and for managing the various assets (devices, etc)</li>
<li>A database (possibly the same as the previous one) for storing the website data</li>
<li>A notification framework for sending notifications (emails, SMS, etc) of various events from the devices</li>
</ul>


<p>Now, one of the things I&rsquo;ve learned about architecture (or, at least I thought I had learned) was to only use what you absolutely need, nothing more. A lean architecture is a good architecture. However, we made some decisions early on which, now, I feel like violate those principles.</p>

<h3>JBoss</h3>

<p>We opted to put the code in an app server for various reasons. We needed a Servlet engine to facilitate the web service, but we decided to use <a href="http://www.jboss.org/jbossas">JBoss AS 7</a> as the app server because we&rsquo;d all had experience with it in the past, and it was being used by the customer currently. We felt like the container could manage all the &ldquo;plumbing&rdquo; (threads, database connections, etc), rather than dealing with it ourselves. I think that decision came more from old architectural design assumptions (&ldquo;three-tiered good, two-tiered bad&rdquo;, &ldquo;managing resources is hard&rdquo;) which are no longer really relevant.</p>

<p>However, more importantly (and I don&rsquo;t mean to bash JBoss here, I think this would be true of any app server), we ended up severely limiting our &ldquo;functional&rdquo; scalability by using an app server. Let me explain:</p>

<p>When I refer to &ldquo;functional&rdquo; vs. &ldquo;theoretical&rdquo; scalability, I&rsquo;m referring to the fact that, while JBoss is certainly very scalable in theory (you can cluster the instances, and add new instances dynamically), in practice, it&rsquo;s really frickin&#8217; difficult to scale. The reason: you can&rsquo;t just &ldquo;add another instance&rdquo;, you need to go through the hell that is cluster configuration to add a new instance, which means, literally, making on the order of a dozen changes to the stock JBoss configuration files.</p>

<p>To put an even finer point on it: the question you should ask yourself in terms of scalability is: if I were to get a call at 2 AM that we need to scale up because the application&rsquo;s pegged, could I scale it quickly and easily, even half-asleep? The answer in this case would be a resounding &ldquo;No!&rdquo;.</p>

<p>The other answer might be to use a deployment system, like <a href="http://www.opscode.com/chef/">Chef</a> or <a href="https://puppetlabs.com/">Puppet</a>, but I&rsquo;ve tried putting together Puppet scripts for doing a JBoss clustered deployment, and it&rsquo;s a nightmare as well.</p>

<p>A lot of this came out of a gig we had auditing another consulting company for a customer. They hired us to talk to the other company with them, because things weren&rsquo;t going well and they needed a second opinion on whether they were being &ldquo;took&rdquo; (we said &ldquo;yes, kinda&rdquo;). However, the most interesting thing was that they had a very similar architecture to ours, but it was seriously slow, so they were constantly having to add in servers in the back end. The sys admin who worked there (and who was probably the smartest guy in the company, as far as I could tell), pointed out that starting up new instances was trivial, because their backend server was a simple process &ndash; no app server, no nothing. He could start it up from the command line if he wanted.</p>

<p>That&rsquo;s how it all <strong><em>should</em></strong> work! It&rsquo;s the Google/Facebook architecture vs. the old-school &ldquo;Big Iron&rdquo; approach. It was a serious &ldquo;Aha!&rdquo; moment for me.</p>

<p>So, what are we getting from using JBoss? EJBs? We are using them, but we don&rsquo;t need them (they&rsquo;re not on the list I mentioned above) &ndash; the web service should be our internal as well as our external API. Thread pools? They used to be complicated, but since JDK 1.5, it&rsquo;s trivial. Database connection pools? Same thing. Caching? We&rsquo;re using a third-party caching mechanism, so no.</p>

<p>Time to ditch JBoss.</p>

<h3>HornetQ</h3>

<p>The queue that comes with JBoss is <a href="http://www.jboss.org/hornetq">HornetQ</a>. It&rsquo;s supposedly a very fast queue, and it comes embedded in JBoss. However, there are several issues with it:</p>

<ul>
<li>It, also, doesn&rsquo;t functionally scale well. You can cluster it, but it&rsquo;s painful, and a configuration nightmare, just like JBoss</li>
<li>It doesn&rsquo;t handle having the queue fill up very gracefully, in my opinion. While I was doing load testing of the app, sometimes the back end would not quite be able to keep up, and when a large number of journal files ended up in the queue, it froze, and needed not just to be restarted, but to have the journal files cleared out first.</li>
<li>It&rsquo;s not trivial swapping out a different queue in JBoss. It&rsquo;s doable, but not very well documented, and it&rsquo;s hard to say how JBoss would handle it.</li>
</ul>


<h3>Spring</h3>

<p>Another questionable architectural decision (and I can say this because I was one of the big advocates) was to use <a href="http://www.springsource.org/">Spring</a>. Now, don&rsquo;t get me wrong &ndash; I <em>love</em> Spring, but it has a tendency to take over once you start using it. We had even talked about, early on, how we weren&rsquo;t going to use Spring for &ldquo;everything&rdquo;, but we ended up using it way too much, IMHO. Plus, I think if we rearchitect everything to be in terms of standalone services, we&rsquo;ll have a lot less need for that sort of configurational complexity.</p>

<h3>Emphasize the Positive</h3>

<p>So, those are the things I think we should ditch. What should our architecture look like? I think we could function well with the web services being in something like <a href="http://tomcat.apache.org/">Tomcat</a> or <a href="http://www.eclipse.org/jetty/">Jetty</a>, with everything else being standalone Java services (i.e., no containers, just POJOs with a main()).</p>

<p>That takes care of the big pieces, but what about the glue to put it together? I was looking around for scalable, distributed queues, when I came across <a href="http://kafka.apache.org/">Kafka</a>. It&rsquo;s not really a queue so much as a pub/sub framework, which you can use like a queue. However, once I started playing with it (which will be the subject of a different post), I came to the realization that it could be used for more than just the queue &ndash; it could be the communication mechanism between the services, basically a communication bus for the architecture. And, it&rsquo;s functionally scalable, because you can add new server instances dynamically using <a href="http://zookeeper.apache.org/">ZooKeeper</a>. We could also reuse ZooKeeper as our own service locater service to allow us to dynamically add new services.</p>

<p>Now, suddenly, things are looking very different. Rather than an app server with all our code deployed on it, we would have compact, self-contained services which communicate via Kafka, find new instances via ZooKeeper, and which scale by just starting up new instances to take on the load. Doing this then implies that the web service front-end would have to be very thin &ndash; just a façade for taking in web service requests, which would then be delegated to the back-end services.</p>

<p>The key would be to define the services well, so they would be small, light, decoupled, and cohesive.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bad Blogger! Bad!]]></title>
    <link href="http://www.geekheads.net/blog/2013/04/11/Bad-Blogger%21-Bad%21/"/>
    <updated>2013-04-11T09:00:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2013/04/11/Bad-Blogger!-Bad!</id>
    <content type="html"><![CDATA[<p>It&rsquo;s been over a year since I last used <a href="http://scriptogr.am">scriptogr.am</a>. Mostly I haven&rsquo;t had much time to actually post &ndash; work has been rather intense, but in a good way. :&ndash;)</p>

<p>Recently, I&rsquo;ve been looking around for blog solutions, and I keep coming back to this.  I&rsquo;ve been getting more and more into using <a href="http://daringfireball.net/projects/markdown/">Markdown</a>, and <a href="http://fletcherpenney.net/multimarkdown/">MultiMarkdown</a> for lots of things, from note taking to creating documents. I&rsquo;ll try to put together another post about that sometime soon. However, for blogging, I wanted to use Markdown, so I looked at <a href="http://jekyllrb.com/">jekyll</a>, which is what <a href="http://pages.github.com/">github pages</a> uses, but it kind of requires some work in terms of setting up the templates, css, etc (although there is a <a href="http://jekyllbootstrap.com/">Jekyll Bootstrap</a> project which helps a lot), and, being the lazy (not to mention busy) guy I am, I decided it was too much work after futzing with it for a couple of hours.</p>

<p>This seems to be the most painless solution, so I&rsquo;m going with it.</p>

<p>Code blocks seem to be handled relatively well:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Foo</span> <span class="o">{</span>
</span><span class='line'>  <span class="kd">private</span> <span class="kt">int</span> <span class="n">bar</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getBar</span><span class="o">()</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">bar</span><span class="o">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>So, I&rsquo;ll stick with this, for now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Beautiful Code]]></title>
    <link href="http://www.geekheads.net/blog/2012/10/01/beautiful-code/"/>
    <updated>2012-10-01T21:11:00-05:00</updated>
    <id>http://www.geekheads.net/blog/2012/10/01/beautiful-code</id>
    <content type="html"><![CDATA[<p>Programmers often talk about code being “beautiful”, but often writing “pretty” code is disparaged as being a luxury that can&rsquo;t be afforded under tight schedules. The result is really ugly code that ends up being difficult to maintain, but most people don&rsquo;t seem to see the correlation between “beauty” and “maintainability”.</p>

<p>Experience has shown me that beautiful code and maintainable code, if not identical, are closely related. The reason, I believe, is very simple: coding is expression. What I mean by this is that, for any given problem that is trying to be solved by code, there are usually many, many different ways to go about solving it within the context of a given language and environment &ndash; there are usually many different solutions which “work”. Because of this, the choice of how to solve the problem is, all else being equal, an aesthetic choice. In other words, given a number of different ways of going about solving the given problem, one way of choosing among all the different possible solutions is to choose the one that seems the “prettiest”, that appeals to the programmers aesthetic style.</p>

<p>This assumes, of course, that the programmer has access to all, or many, of the possible solutions. A less-experienced or less-talented programmer may only see one possible way of solving the problem, or may be too lazy or unmotivated to find or utilize more than one possible solution &ndash; this is one source of much bad, “ugly”, and unmaintainable code. However, when the programmer is talented and/or experienced enough, and properly motivated, the multiple possibilities open up, and the choice becomes available. This, incidentally, is one difference between a good, talented programmer and a hack &ndash; the talented programmer will always be aware of the various possible solutions available, and will have a good grasp of the consequences of each decision.</p>

<p>So, how does this make the choice an aesthetic one, and why would the “prettiest” choice turn out to be the best? Because, as I said earlier, code is expression. Who or what do we write code for? Is it just to be turned into machine code and run? No, because if that were the case, we&rsquo;d all be writing in assembler. No, we write code for humans &ndash; other people who will be looking at the code, and maintaining it. Good code is written to express the solution to a particular problem in the clearest possible manner to the people who will be reading the code later. A good programmer writes the code in such a way as to express their view of the most straightforward and conceptually clear way of solving the given problem, so that the person reading the code will easily understand what is being done, why it&rsquo;s being done, and why it&rsquo;s being done in that particular way. That&rsquo;s not to say that the way it&rsquo;s being done is, somehow, the best way of doing it, but simply that it expresses the problem and the solution in a way that the reader can grasp easily.</p>

<p>However, well-written code does more than that: it also expresses the aesthetic choices of the programmer in such a way that the person reading the code can use those aesthetic choices to better understand the intent of the code, and to see how all the pieces of code fit together. If the code is written with no, or multiple, aesthetic styles, then the code becomes more difficult to understand as the reader tries to follow one set of aesthetic choices in one part of the code, and then a completely different set of choices in another part.</p>

<p>This is no different than what a writer does with a novel &ndash; a given problem exists (for example, there are two characters which need to interact in such a way as to move the plot in the desired direction), there are multiple solutions available (the characters can interact in many different ways, choose not to interact, etc), and the novelist must choose the solution that not only solves the problem, but that does it in a way that is clear to the reader and which expresses the aesthetic style of the writer. If the writer changes styles, where on one page things seem to go one way, but on another page the aesthetic style changes abruptly, then the novel becomes both unpleasant to read and difficult to follow. The same is true of code &ndash; the reader needs to be able to get a feeling for the aesthetic style of the code, and use that to understand how the different pieces work and flow together.</p>
]]></content>
  </entry>
  
</feed>
